{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "ing_path=r\"C:\\Users\\greys\\projects\\azure-swa\\my-static-web-app\\api\\src\\external\\ingredients\\v1\\ingredients.xlsx\"\n",
    "prd_path=r\"C:\\Users\\greys\\projects\\azure-swa\\my-static-web-app\\api\\src\\external\\products\\v2\\products.xlsx\"\n",
    "\n",
    "# Load your Excel file\n",
    "ing_df = pd.read_excel(ing_path)\n",
    "ing_df['name'] = ing_df['name'].apply(lambda x: str(x).lower().replace(\" \",\"_\"))\n",
    "\n",
    "# Load your Excel file\n",
    "prd_df = pd.read_excel(prd_path)\n",
    "\n",
    "# TODO: Include alias into ingredient names\n",
    "def apply_like_ratio(row):\n",
    "    ings=literal_eval(row.ingredient_list)\n",
    "    prd_ings=ing_df.loc[ing_df.name.isin(ings)]\n",
    "    prd_ings=prd_ings.loc[prd_ings.dislikes >0]\n",
    "    prd_ings[\"like_ratio\"]=prd_ings.likes / (prd_ings.likes + prd_ings.dislikes)\n",
    "    row[\"like_ratio\"]=prd_ings.like_ratio.mean()\n",
    "    return row\n",
    "\n",
    "qant_list = prd_df.dropna(subset=[\"ingredient_list\"]).apply(apply_like_ratio, axis=1)\n",
    "qant_list.sort_values(\"like_ratio\", ascending=False)\n",
    "    \n",
    "qant_list.shape\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "# Assuming df is your DataFrame and 'like_ratio' is your column of interest\n",
    "\n",
    "qant_list['like_ratio'].plot(kind='hist', nbins=50, title='Like Ratio Histogram')\n",
    "\n",
    "\n",
    "prd_df.type.unique()\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "\n",
    "for typ, group_df in qant_list.groupby('type'):\n",
    "    fig = group_df['like_ratio'].plot(kind='hist', nbins=50, title=f'Like Ratio Histogram for Type: {typ}')\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'str',\n",
       " 'brand': 'str',\n",
       " 'type': 'str',\n",
       " 'description': 'str',\n",
       " 'benefit_list': 'dict',\n",
       " 'aspect_list': 'list',\n",
       " 'ingredient_list': 'list',\n",
       " 'concern_list': 'dict',\n",
       " 'directions': 'str'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipeline.utils.helpers import *\n",
    "read_yaml('data-contract.yml')['Product']['columns']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>benefit_list</th>\n",
       "      <th>aspect_list</th>\n",
       "      <th>ingredient_list</th>\n",
       "      <th>concern_list</th>\n",
       "      <th>directions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Niacinamide 10% + Zinc 1%</td>\n",
       "      <td>The Ordinary</td>\n",
       "      <td>Facial Treatment</td>\n",
       "      <td>vegan and cruelty-free facial treatment that c...</td>\n",
       "      <td>{'Good For Oily Skin': ['Niacinamide'], 'Reduc...</td>\n",
       "      <td>['alcohol_free', 'silicon_free', 'contains_fra...</td>\n",
       "      <td>['water', 'niacinamide', 'pentylene_glycol', '...</td>\n",
       "      <td>{'May Cause Irritation': ['Isoceteth-20']}</td>\n",
       "      <td>Apply to entire face morning and evening befor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advanced Snail 96 Mucin Power Essence</td>\n",
       "      <td>COSRX</td>\n",
       "      <td>Essence</td>\n",
       "      <td>cruelty-free essence that contains hyaluronic ...</td>\n",
       "      <td>{'Reduces Redness': ['Snail Secretion Filtrate...</td>\n",
       "      <td>['alcohol_free', 'silicon_free', 'fragrance_fr...</td>\n",
       "      <td>['snail_secretion_filtrate', 'betaine', 'butyl...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Niacinamide 10% + Zinc 1%</td>\n",
       "      <td>The Ordinary</td>\n",
       "      <td>Facial Treatment</td>\n",
       "      <td>vegan and cruelty-free facial treatment that c...</td>\n",
       "      <td>{'Good For Oily Skin': ['Niacinamide'], 'Reduc...</td>\n",
       "      <td>['alcohol_free', 'silicon_free', 'contains_fra...</td>\n",
       "      <td>['water', 'niacinamide', 'pentylene_glycol', '...</td>\n",
       "      <td>{'May Cause Irritation': ['Isoceteth-20']}</td>\n",
       "      <td>Apply to entire face morning and evening befor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Advanced Snail 96 Mucin Power Essence</td>\n",
       "      <td>COSRX</td>\n",
       "      <td>Essence</td>\n",
       "      <td>cruelty-free essence that contains hyaluronic ...</td>\n",
       "      <td>{'Reduces Redness': ['Snail Secretion Filtrate...</td>\n",
       "      <td>['alcohol_free', 'silicon_free', 'fragrance_fr...</td>\n",
       "      <td>['snail_secretion_filtrate', 'betaine', 'butyl...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10018</th>\n",
       "      <td>Baby Moisturizing Cream</td>\n",
       "      <td>CeraVe</td>\n",
       "      <td>General Moisturizer</td>\n",
       "      <td>general moisturizer that contains ceramides an...</td>\n",
       "      <td>{'Reduces Redness': ['Ceramide NP', 'Ceramide ...</td>\n",
       "      <td>['alcohol_free', 'contains_silicon', 'contains...</td>\n",
       "      <td>['water', 'glycerin', 'cetearyl_alcohol', 'cap...</td>\n",
       "      <td>{'May Worsen Oily Skin': ['Petrolatum'], 'May ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10019</th>\n",
       "      <td>Transforming Walnut Scrub</td>\n",
       "      <td>Olehenriksen</td>\n",
       "      <td>Exfoliator</td>\n",
       "      <td>cruelty-free exfoliator that contains aha, exf...</td>\n",
       "      <td>{'Helps Reduce Irritation': ['Chamomilla Recut...</td>\n",
       "      <td>['contains_alcohol', 'silicon_free', 'contains...</td>\n",
       "      <td>['water', 'cocamidopropyl_hydroxysultaine', 'j...</td>\n",
       "      <td>{'May Worsen Dry Skin': ['Sodium Chloride', 'C...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10020</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10021</th>\n",
       "      <td>Clear Body Break-Out Free Liquid Lotion Sunscr...</td>\n",
       "      <td>Neutrogena</td>\n",
       "      <td>Sunscreen</td>\n",
       "      <td>sunscreen that contains exfoliants and spf. it...</td>\n",
       "      <td>{'Helps Reduce Irritation': ['Bisabolol']}</td>\n",
       "      <td>['alcohol_free', 'contains_silicon', 'contains...</td>\n",
       "      <td>['butyl_methoxydibenzoylmethane_2.5%', 'homosa...</td>\n",
       "      <td>{'May Cause Acne': ['Ethylhexyl Stearate'], 'M...</td>\n",
       "      <td>1. Apply liberally 15 minutes before sun expos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10022</th>\n",
       "      <td>Triple Action Cleansing Water</td>\n",
       "      <td>Sephora Collection</td>\n",
       "      <td>Makeup Remover</td>\n",
       "      <td>vegan makeup remover that contains aha. it doe...</td>\n",
       "      <td>{'Helps Reduce Irritation': ['Panthenol', 'Cal...</td>\n",
       "      <td>['alcohol_free', 'contains_silicon', 'contains...</td>\n",
       "      <td>['water', 'peg-6_caprylic/capric_glycerides', ...</td>\n",
       "      <td>{'May Worsen Dry Skin': ['Sodium Chloride', 'C...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10023 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name               brand  \\\n",
       "                                                                               \n",
       "0                              Niacinamide 10% + Zinc 1%        The Ordinary   \n",
       "1                  Advanced Snail 96 Mucin Power Essence               COSRX   \n",
       "2                              Niacinamide 10% + Zinc 1%        The Ordinary   \n",
       "3                  Advanced Snail 96 Mucin Power Essence               COSRX   \n",
       "4                                                   None                None   \n",
       "...                                                  ...                 ...   \n",
       "10018                            Baby Moisturizing Cream              CeraVe   \n",
       "10019                          Transforming Walnut Scrub        Olehenriksen   \n",
       "10020                                               None                None   \n",
       "10021  Clear Body Break-Out Free Liquid Lotion Sunscr...          Neutrogena   \n",
       "10022                      Triple Action Cleansing Water  Sephora Collection   \n",
       "\n",
       "                      type                                        description  \\\n",
       "                                                                                \n",
       "0         Facial Treatment  vegan and cruelty-free facial treatment that c...   \n",
       "1                  Essence  cruelty-free essence that contains hyaluronic ...   \n",
       "2         Facial Treatment  vegan and cruelty-free facial treatment that c...   \n",
       "3                  Essence  cruelty-free essence that contains hyaluronic ...   \n",
       "4                     None                                               None   \n",
       "...                    ...                                                ...   \n",
       "10018  General Moisturizer  general moisturizer that contains ceramides an...   \n",
       "10019           Exfoliator  cruelty-free exfoliator that contains aha, exf...   \n",
       "10020                 None                                               None   \n",
       "10021            Sunscreen  sunscreen that contains exfoliants and spf. it...   \n",
       "10022       Makeup Remover  vegan makeup remover that contains aha. it doe...   \n",
       "\n",
       "                                            benefit_list  \\\n",
       "                                                           \n",
       "0      {'Good For Oily Skin': ['Niacinamide'], 'Reduc...   \n",
       "1      {'Reduces Redness': ['Snail Secretion Filtrate...   \n",
       "2      {'Good For Oily Skin': ['Niacinamide'], 'Reduc...   \n",
       "3      {'Reduces Redness': ['Snail Secretion Filtrate...   \n",
       "4                                                   None   \n",
       "...                                                  ...   \n",
       "10018  {'Reduces Redness': ['Ceramide NP', 'Ceramide ...   \n",
       "10019  {'Helps Reduce Irritation': ['Chamomilla Recut...   \n",
       "10020                                               None   \n",
       "10021         {'Helps Reduce Irritation': ['Bisabolol']}   \n",
       "10022  {'Helps Reduce Irritation': ['Panthenol', 'Cal...   \n",
       "\n",
       "                                             aspect_list  \\\n",
       "                                                           \n",
       "0      ['alcohol_free', 'silicon_free', 'contains_fra...   \n",
       "1      ['alcohol_free', 'silicon_free', 'fragrance_fr...   \n",
       "2      ['alcohol_free', 'silicon_free', 'contains_fra...   \n",
       "3      ['alcohol_free', 'silicon_free', 'fragrance_fr...   \n",
       "4                                                   None   \n",
       "...                                                  ...   \n",
       "10018  ['alcohol_free', 'contains_silicon', 'contains...   \n",
       "10019  ['contains_alcohol', 'silicon_free', 'contains...   \n",
       "10020                                               None   \n",
       "10021  ['alcohol_free', 'contains_silicon', 'contains...   \n",
       "10022  ['alcohol_free', 'contains_silicon', 'contains...   \n",
       "\n",
       "                                         ingredient_list  \\\n",
       "                                                           \n",
       "0      ['water', 'niacinamide', 'pentylene_glycol', '...   \n",
       "1      ['snail_secretion_filtrate', 'betaine', 'butyl...   \n",
       "2      ['water', 'niacinamide', 'pentylene_glycol', '...   \n",
       "3      ['snail_secretion_filtrate', 'betaine', 'butyl...   \n",
       "4                                                   None   \n",
       "...                                                  ...   \n",
       "10018  ['water', 'glycerin', 'cetearyl_alcohol', 'cap...   \n",
       "10019  ['water', 'cocamidopropyl_hydroxysultaine', 'j...   \n",
       "10020                                               None   \n",
       "10021  ['butyl_methoxydibenzoylmethane_2.5%', 'homosa...   \n",
       "10022  ['water', 'peg-6_caprylic/capric_glycerides', ...   \n",
       "\n",
       "                                            concern_list  \\\n",
       "                                                           \n",
       "0             {'May Cause Irritation': ['Isoceteth-20']}   \n",
       "1                                                   None   \n",
       "2             {'May Cause Irritation': ['Isoceteth-20']}   \n",
       "3                                                   None   \n",
       "4                                                   None   \n",
       "...                                                  ...   \n",
       "10018  {'May Worsen Oily Skin': ['Petrolatum'], 'May ...   \n",
       "10019  {'May Worsen Dry Skin': ['Sodium Chloride', 'C...   \n",
       "10020                                               None   \n",
       "10021  {'May Cause Acne': ['Ethylhexyl Stearate'], 'M...   \n",
       "10022  {'May Worsen Dry Skin': ['Sodium Chloride', 'C...   \n",
       "\n",
       "                                              directions  \n",
       "                                                          \n",
       "0      Apply to entire face morning and evening befor...  \n",
       "1                                                   None  \n",
       "2      Apply to entire face morning and evening befor...  \n",
       "3                                                   None  \n",
       "4                                                   None  \n",
       "...                                                  ...  \n",
       "10018                                               None  \n",
       "10019                                               None  \n",
       "10020                                               None  \n",
       "10021  1. Apply liberally 15 minutes before sun expos...  \n",
       "10022                                               None  \n",
       "\n",
       "[10023 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipeline.data import Ingredient, Product\n",
    "prd = Product('data-contract.yml')\n",
    "# prd.store_processed()\n",
    "prd.processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prd.processed\n",
    "df.memory_usage(deep=True).sum() / (1024**3)\n",
    "df.to_excel('./products.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data not found. Storing processed data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greysonnewton/Library/CloudStorage/OneDrive-Personal/CNTX/cosneti/pipeline/data/datasets.py:128: FutureWarning: Passing a dict as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  data = data.apply(self.__scrub_desc, axis=1)\\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                0.01\n",
      "alias              99.97\n",
      "type               13.38\n",
      "description         0.01\n",
      "n_products         81.00\n",
      "likes               0.01\n",
      "dislikes            0.01\n",
      "rating             98.87\n",
      "concentration      99.21\n",
      "category           74.54\n",
      "references         98.85\n",
      "cosing_data        74.56\n",
      "common_products    10.18\n",
      "dtype: float64\n",
      "50.04\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error converting column \"n_products\" to bytes using encoding UTF8. Original error: bad argument type for built-in operation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/backends.py:135\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/dataframe/io/parquet/core.py:548\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, columns, filters, categories, index, storage_options, engine, use_nullable_dtypes, calculate_divisions, ignore_metadata_file, metadata_task_size, split_row_groups, blocksize, aggregate_files, parquet_file_extension, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m     blocksize \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m read_metadata_result \u001b[39m=\u001b[39m engine\u001b[39m.\u001b[39;49mread_metadata(\n\u001b[1;32m    549\u001b[0m     fs,\n\u001b[1;32m    550\u001b[0m     paths,\n\u001b[1;32m    551\u001b[0m     categories\u001b[39m=\u001b[39;49mcategories,\n\u001b[1;32m    552\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    553\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39;49muse_nullable_dtypes,\n\u001b[1;32m    554\u001b[0m     gather_statistics\u001b[39m=\u001b[39;49mcalculate_divisions,\n\u001b[1;32m    555\u001b[0m     filters\u001b[39m=\u001b[39;49mfilters,\n\u001b[1;32m    556\u001b[0m     split_row_groups\u001b[39m=\u001b[39;49msplit_row_groups,\n\u001b[1;32m    557\u001b[0m     blocksize\u001b[39m=\u001b[39;49mblocksize,\n\u001b[1;32m    558\u001b[0m     aggregate_files\u001b[39m=\u001b[39;49maggregate_files,\n\u001b[1;32m    559\u001b[0m     ignore_metadata_file\u001b[39m=\u001b[39;49mignore_metadata_file,\n\u001b[1;32m    560\u001b[0m     metadata_task_size\u001b[39m=\u001b[39;49mmetadata_task_size,\n\u001b[1;32m    561\u001b[0m     parquet_file_extension\u001b[39m=\u001b[39;49mparquet_file_extension,\n\u001b[1;32m    562\u001b[0m     dataset\u001b[39m=\u001b[39;49mdataset_options,\n\u001b[1;32m    563\u001b[0m     read\u001b[39m=\u001b[39;49mread_options,\n\u001b[1;32m    564\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mother_options,\n\u001b[1;32m    565\u001b[0m )\n\u001b[1;32m    567\u001b[0m \u001b[39m# In the future, we may want to give the engine the\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[39m# option to return a dedicated element for `common_kwargs`.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[39m# However, to avoid breaking the API, we just embed this\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[39m# data in the first element of `parts` for now.\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[39m# The logic below is inteded to handle backward and forward\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[39m# compatibility with a user-defined engine.\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/dataframe/io/parquet/fastparquet.py:908\u001b[0m, in \u001b[0;36mFastParquetEngine.read_metadata\u001b[0;34m(cls, fs, paths, categories, index, use_nullable_dtypes, gather_statistics, filters, split_row_groups, blocksize, aggregate_files, ignore_metadata_file, metadata_task_size, parquet_file_extension, **kwargs)\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[39m# Stage 1: Collect general dataset information\u001b[39;00m\n\u001b[0;32m--> 908\u001b[0m dataset_info \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_collect_dataset_info(\n\u001b[1;32m    909\u001b[0m     paths,\n\u001b[1;32m    910\u001b[0m     fs,\n\u001b[1;32m    911\u001b[0m     categories,\n\u001b[1;32m    912\u001b[0m     index,\n\u001b[1;32m    913\u001b[0m     gather_statistics,\n\u001b[1;32m    914\u001b[0m     filters,\n\u001b[1;32m    915\u001b[0m     split_row_groups,\n\u001b[1;32m    916\u001b[0m     blocksize,\n\u001b[1;32m    917\u001b[0m     aggregate_files,\n\u001b[1;32m    918\u001b[0m     ignore_metadata_file,\n\u001b[1;32m    919\u001b[0m     metadata_task_size,\n\u001b[1;32m    920\u001b[0m     parquet_file_extension,\n\u001b[1;32m    921\u001b[0m     kwargs,\n\u001b[1;32m    922\u001b[0m )\n\u001b[1;32m    924\u001b[0m \u001b[39m# Stage 2: Generate output `meta`\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/dataframe/io/parquet/fastparquet.py:449\u001b[0m, in \u001b[0;36mFastParquetEngine._collect_dataset_info\u001b[0;34m(cls, paths, fs, categories, index, gather_statistics, filters, split_row_groups, blocksize, aggregate_files, ignore_metadata_file, metadata_task_size, parquet_file_extension, kwargs)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    446\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mNo files satisfy the `parquet_file_extension` criteria \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(files must end with \u001b[39m\u001b[39m{\u001b[39;00mparquet_file_extension\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         )\n\u001b[0;32m--> 449\u001b[0m pf \u001b[39m=\u001b[39m ParquetFile(\n\u001b[1;32m    450\u001b[0m     paths[:\u001b[39m1\u001b[39;49m], open_with\u001b[39m=\u001b[39;49mfs\u001b[39m.\u001b[39;49mopen, root\u001b[39m=\u001b[39;49mbase, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdataset_kwargs\n\u001b[1;32m    451\u001b[0m )\n\u001b[1;32m    452\u001b[0m scheme \u001b[39m=\u001b[39m get_file_scheme(fns)\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/fastparquet/api.py:123\u001b[0m, in \u001b[0;36mParquetFile.__init__\u001b[0;34m(self, fn, verify, open_with, root, sep, fs, pandas_nulls, dtypes)\u001b[0m\n\u001b[1;32m    122\u001b[0m     root \u001b[39m=\u001b[39m fs\u001b[39m.\u001b[39m_strip_protocol(root)\n\u001b[0;32m--> 123\u001b[0m basepath, fmd \u001b[39m=\u001b[39m metadata_from_many(fn, verify_schema\u001b[39m=\u001b[39;49mverify,\n\u001b[1;32m    124\u001b[0m                                    open_with\u001b[39m=\u001b[39;49mopen_with, root\u001b[39m=\u001b[39;49mroot,\n\u001b[1;32m    125\u001b[0m                                    fs\u001b[39m=\u001b[39;49mfs)\n\u001b[1;32m    126\u001b[0m writer\u001b[39m.\u001b[39mconsolidate_categories(fmd)\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/fastparquet/util.py:195\u001b[0m, in \u001b[0;36mmetadata_from_many\u001b[0;34m(file_list, verify_schema, open_with, root, fs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mif\u001b[39;00m verify_schema \u001b[39mor\u001b[39;00m fs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(file_list) \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m--> 195\u001b[0m     pfs \u001b[39m=\u001b[39m [api\u001b[39m.\u001b[39mParquetFile(fn, open_with\u001b[39m=\u001b[39mopen_with) \u001b[39mfor\u001b[39;00m fn \u001b[39min\u001b[39;00m file_list]\n\u001b[1;32m    196\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[39m# activate new code path here\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/fastparquet/util.py:195\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mif\u001b[39;00m verify_schema \u001b[39mor\u001b[39;00m fs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(file_list) \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m--> 195\u001b[0m     pfs \u001b[39m=\u001b[39m [api\u001b[39m.\u001b[39;49mParquetFile(fn, open_with\u001b[39m=\u001b[39;49mopen_with) \u001b[39mfor\u001b[39;00m fn \u001b[39min\u001b[39;00m file_list]\n\u001b[1;32m    196\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[39m# activate new code path here\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/fastparquet/api.py:143\u001b[0m, in \u001b[0;36mParquetFile.__init__\u001b[0;34m(self, fn, verify, open_with, root, sep, fs, pandas_nulls, dtypes)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mwith\u001b[39;00m open_with(fn, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_header(f, verify)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m root:\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/fastparquet/api.py:224\u001b[0m, in \u001b[0;36mParquetFile._parse_header\u001b[0;34m(self, f, verify)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39m# for rg in fmd.row_groups:\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m \u001b[39mfor\u001b[39;00m rg \u001b[39min\u001b[39;00m fmd[\u001b[39m4\u001b[39m]:\n\u001b[1;32m    225\u001b[0m     \u001b[39m# chunks = rg.columns\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     chunks \u001b[39m=\u001b[39m rg[\u001b[39m1\u001b[39m]    \n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/CNTX/cosneti/pipeline/data/datasets.py:58\u001b[0m, in \u001b[0;36mDataset.processed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery(\u001b[39m'\u001b[39;49m\u001b[39mprocessed\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/CNTX/cosneti/pipeline/data/datasets.py:26\u001b[0m, in \u001b[0;36mDataset.query\u001b[0;34m(self, query, apply_dtypes)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mquery\u001b[39m(\u001b[39mself\u001b[39m, query, apply_dtypes\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> 26\u001b[0m     query_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollection\u001b[39m.\u001b[39;49mitem(\n\u001b[1;32m     27\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcfg[\u001b[39m'\u001b[39;49m\u001b[39mcollections\u001b[39;49m\u001b[39m'\u001b[39;49m][query])\u001b[39m.\u001b[39mto_pandas()\n\u001b[1;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m apply_column_types(query_result, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns) \u001b[39mif\u001b[39;00m apply_dtypes \u001b[39melse\u001b[39;00m query_result\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/pystore/collection.py:76\u001b[0m, in \u001b[0;36mCollection.item\u001b[0;34m(self, item, snapshot, filters, columns)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mitem\u001b[39m(\u001b[39mself\u001b[39m, item, snapshot\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, filters\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, columns\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m Item(item, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatastore, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollection,\n\u001b[1;32m     77\u001b[0m                 snapshot, filters, columns, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/pystore/item.py:60\u001b[0m, in \u001b[0;36mItem.__init__\u001b[0;34m(self, item, datastore, collection, snapshot, filters, columns, engine)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mread_metadata(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path)\n\u001b[0;32m---> 60\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m dd\u001b[39m.\u001b[39;49mread_parquet(\n\u001b[1;32m     61\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_path, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine, filters\u001b[39m=\u001b[39;49mfilters, columns\u001b[39m=\u001b[39;49mcolumns)\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/backends.py:137\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(e)(\n\u001b[1;32m    138\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling the \u001b[39m\u001b[39m{\u001b[39;00mfuncname(func)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmethod registered to the \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackend\u001b[39m}\u001b[39;00m\u001b[39m backend.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOriginal Message: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: An error occurred while calling the read_parquet method registered to the pandas backend.\nOriginal Message: 'NoneType' object is not iterable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m ing \u001b[39m=\u001b[39m Ingredient(\u001b[39m'\u001b[39m\u001b[39mdata-contract.yml\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# prd.store_processed()\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m ing\u001b[39m.\u001b[39;49mprocessed\u001b[39m.\u001b[39mto_excel(\u001b[39m'\u001b[39m\u001b[39m./ingredients.xlsx\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/CNTX/cosneti/pipeline/data/datasets.py:61\u001b[0m, in \u001b[0;36mDataset.processed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     60\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProcessed data not found. Storing processed data...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore_processed(\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     62\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery(\u001b[39m'\u001b[39m\u001b[39mprocessed\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/CNTX/cosneti/pipeline/data/datasets.py:139\u001b[0m, in \u001b[0;36mIngredient.store_processed\u001b[0;34m(self, overwrite)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mprint\u001b[39m(all_nans(data))\n\u001b[1;32m    137\u001b[0m data\u001b[39m.\u001b[39mto_excel(\n\u001b[1;32m    138\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m/Users/greysonnewton/Library/CloudStorage/OneDrive-Personal/CNTX/cosneti/external/prod-ing/ingredients.xlsx\u001b[39m\u001b[39m'\u001b[39m,index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollection\u001b[39m.\u001b[39;49mwrite(\n\u001b[1;32m    140\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcfg[\u001b[39m'\u001b[39;49m\u001b[39mcollections\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mprocessed\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    141\u001b[0m     data,\n\u001b[1;32m    142\u001b[0m     metadata\u001b[39m=\u001b[39;49m{\n\u001b[1;32m    143\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39msource\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mscraped\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    144\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mlast_updated\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39m2022-12-01\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m    145\u001b[0m     },\n\u001b[1;32m    146\u001b[0m     overwrite\u001b[39m=\u001b[39;49moverwrite\n\u001b[1;32m    147\u001b[0m )\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/pystore/collection.py:140\u001b[0m, in \u001b[0;36mCollection.write\u001b[0;34m(self, item, data, metadata, npartitions, chunksize, overwrite, epochdate, reload_items, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m         npartitions \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\n\u001b[1;32m    137\u001b[0m             \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m memusage \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m config\u001b[39m.\u001b[39mPARTITION_SIZE)\n\u001b[1;32m    138\u001b[0m         data \u001b[39m=\u001b[39m dd\u001b[39m.\u001b[39mfrom_pandas(data, npartitions\u001b[39m=\u001b[39mnpartitions)\n\u001b[0;32m--> 140\u001b[0m dd\u001b[39m.\u001b[39;49mto_parquet(data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_item_path(item, as_string\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[1;32m    141\u001b[0m               compression\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msnappy\u001b[39;49m\u001b[39m\"\u001b[39;49m, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m utils\u001b[39m.\u001b[39mwrite_metadata(utils\u001b[39m.\u001b[39mmake_path(\n\u001b[1;32m    144\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatastore, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollection, item), metadata)\n\u001b[1;32m    146\u001b[0m \u001b[39m# update items\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/dataframe/io/parquet/core.py:1069\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, write_index, append, overwrite, ignore_divisions, partition_on, storage_options, custom_metadata, write_metadata_file, compute, compute_kwargs, schema, name_function, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m   1066\u001b[0m out \u001b[39m=\u001b[39m Scalar(graph, final_name, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1068\u001b[0m \u001b[39mif\u001b[39;00m compute:\n\u001b[0;32m-> 1069\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39;49mcompute(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcompute_kwargs)\n\u001b[1;32m   1071\u001b[0m \u001b[39m# Invalidate the filesystem listing cache for the output path after write.\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[39m# We do this before returning, even if `compute=False`. This helps ensure\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[39m# that reading files that were just written succeeds.\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m fs\u001b[39m.\u001b[39minvalidate_cache(path)\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/base.py:314\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    291\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \n\u001b[1;32m    293\u001b[0m \u001b[39m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39m    dask.base.compute\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     (result,) \u001b[39m=\u001b[39m compute(\u001b[39mself\u001b[39;49m, traverse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    315\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/base.py:599\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    596\u001b[0m     keys\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_keys__())\n\u001b[1;32m    597\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 599\u001b[0m results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    600\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(pool, multiprocessing\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mPool):\n\u001b[1;32m     87\u001b[0m         pool \u001b[39m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 89\u001b[0m results \u001b[39m=\u001b[39m get_async(\n\u001b[1;32m     90\u001b[0m     pool\u001b[39m.\u001b[39;49msubmit,\n\u001b[1;32m     91\u001b[0m     pool\u001b[39m.\u001b[39;49m_max_workers,\n\u001b[1;32m     92\u001b[0m     dsk,\n\u001b[1;32m     93\u001b[0m     keys,\n\u001b[1;32m     94\u001b[0m     cache\u001b[39m=\u001b[39;49mcache,\n\u001b[1;32m     95\u001b[0m     get_id\u001b[39m=\u001b[39;49m_thread_get_id,\n\u001b[1;32m     96\u001b[0m     pack_exception\u001b[39m=\u001b[39;49mpack_exception,\n\u001b[1;32m     97\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     98\u001b[0m )\n\u001b[1;32m    100\u001b[0m \u001b[39m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m         _execute_task(task, data)  \u001b[39m# Re-execute locally\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         raise_exception(exc, tb)\n\u001b[1;32m    512\u001b[0m res, worker_id \u001b[39m=\u001b[39m loads(res_info)\n\u001b[1;32m    513\u001b[0m state[\u001b[39m\"\u001b[39m\u001b[39mcache\u001b[39m\u001b[39m\"\u001b[39m][key] \u001b[39m=\u001b[39m res\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mif\u001b[39;00m exc\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[1;32m    318\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 319\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     task, data \u001b[39m=\u001b[39m loads(task_info)\n\u001b[0;32m--> 224\u001b[0m     result \u001b[39m=\u001b[39m _execute_task(task, data)\n\u001b[1;32m    225\u001b[0m     \u001b[39mid\u001b[39m \u001b[39m=\u001b[39m get_id()\n\u001b[1;32m    226\u001b[0m     result \u001b[39m=\u001b[39m dumps((result, \u001b[39mid\u001b[39m))\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m(_execute_task(a, cache) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/optimization.py:990\u001b[0m, in \u001b[0;36mSubgraphCallable.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minkeys):\n\u001b[1;32m    989\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m args, got \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minkeys), \u001b[39mlen\u001b[39m(args)))\n\u001b[0;32m--> 990\u001b[0m \u001b[39mreturn\u001b[39;00m core\u001b[39m.\u001b[39;49mget(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdsk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutkey, \u001b[39mdict\u001b[39;49m(\u001b[39mzip\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minkeys, args)))\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/core.py:149\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, out, cache)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m toposort(dsk):\n\u001b[1;32m    148\u001b[0m     task \u001b[39m=\u001b[39m dsk[key]\n\u001b[0;32m--> 149\u001b[0m     result \u001b[39m=\u001b[39m _execute_task(task, cache)\n\u001b[1;32m    150\u001b[0m     cache[key] \u001b[39m=\u001b[39m result\n\u001b[1;32m    151\u001b[0m result \u001b[39m=\u001b[39m _execute_task(out, cache)\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m(_execute_task(a, cache) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/dataframe/io/parquet/core.py:171\u001b[0m, in \u001b[0;36mToParquetFunctionWrapper.__call__\u001b[0;34m(self, df, block_index)\u001b[0m\n\u001b[1;32m    164\u001b[0m filename \u001b[39m=\u001b[39m (\n\u001b[1;32m    165\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpart.\u001b[39m\u001b[39m{\u001b[39;00mpart_i\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mi_offset\u001b[39m}\u001b[39;00m\u001b[39m.parquet\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname_function \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname_function(part_i \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mi_offset)\n\u001b[1;32m    168\u001b[0m )\n\u001b[1;32m    170\u001b[0m \u001b[39m# Write out data\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine\u001b[39m.\u001b[39;49mwrite_partition(\n\u001b[1;32m    172\u001b[0m     df,\n\u001b[1;32m    173\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath,\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfs,\n\u001b[1;32m    175\u001b[0m     filename,\n\u001b[1;32m    176\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartition_on,\n\u001b[1;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_metadata_file,\n\u001b[1;32m    178\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(\u001b[39mdict\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs_pass, head\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39mif\u001b[39;49;00m part_i \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs_pass),\n\u001b[1;32m    179\u001b[0m )\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/dask/dataframe/io/parquet/fastparquet.py:1336\u001b[0m, in \u001b[0;36mFastParquetEngine.write_partition\u001b[0;34m(cls, df, path, fs, filename, partition_on, return_metadata, fmd, compression, custom_metadata, **kwargs)\u001b[0m\n\u001b[1;32m   1334\u001b[0m \u001b[39mwith\u001b[39;00m fs\u001b[39m.\u001b[39mopen(fs\u001b[39m.\u001b[39msep\u001b[39m.\u001b[39mjoin([path, filename]), \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m fil:\n\u001b[1;32m   1335\u001b[0m     fmd\u001b[39m.\u001b[39mnum_rows \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(df)\n\u001b[0;32m-> 1336\u001b[0m     rg \u001b[39m=\u001b[39m make_part_file(\n\u001b[1;32m   1337\u001b[0m         fil, df, fmd\u001b[39m.\u001b[39;49mschema, compression\u001b[39m=\u001b[39;49mcompression, fmd\u001b[39m=\u001b[39;49mfmd\n\u001b[1;32m   1338\u001b[0m     )\n\u001b[1;32m   1339\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m rg\u001b[39m.\u001b[39mcolumns:\n\u001b[1;32m   1340\u001b[0m     chunk\u001b[39m.\u001b[39mfile_path \u001b[39m=\u001b[39m filename\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/fastparquet/writer.py:797\u001b[0m, in \u001b[0;36mmake_part_file\u001b[0;34m(f, data, schema, compression, fmd, stats)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mwith\u001b[39;00m f \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    796\u001b[0m     f\u001b[39m.\u001b[39mwrite(MARKER)\n\u001b[0;32m--> 797\u001b[0m     rg \u001b[39m=\u001b[39m make_row_group(f, data, schema, compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    798\u001b[0m                         stats\u001b[39m=\u001b[39;49mstats)\n\u001b[1;32m    799\u001b[0m     \u001b[39mif\u001b[39;00m fmd \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    800\u001b[0m         fmd \u001b[39m=\u001b[39m parquet_thrift\u001b[39m.\u001b[39mFileMetaData(num_rows\u001b[39m=\u001b[39mrg\u001b[39m.\u001b[39mnum_rows,\n\u001b[1;32m    801\u001b[0m                                           schema\u001b[39m=\u001b[39mschema,\n\u001b[1;32m    802\u001b[0m                                           version\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    803\u001b[0m                                           created_by\u001b[39m=\u001b[39mcreated_by,\n\u001b[1;32m    804\u001b[0m                                           row_groups\u001b[39m=\u001b[39m[rg],\n\u001b[1;32m    805\u001b[0m                                           i32list\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/fastparquet/writer.py:782\u001b[0m, in \u001b[0;36mmake_row_group\u001b[0;34m(f, data, schema, compression, stats)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    781\u001b[0m             st \u001b[39m=\u001b[39m column\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m stats\n\u001b[0;32m--> 782\u001b[0m         chunk \u001b[39m=\u001b[39m write_column(f, coldata, column,\n\u001b[1;32m    783\u001b[0m                              compression\u001b[39m=\u001b[39;49mcomp, stats\u001b[39m=\u001b[39;49mst)\n\u001b[1;32m    784\u001b[0m         cols\u001b[39m.\u001b[39mappend(chunk)\n\u001b[1;32m    785\u001b[0m rg \u001b[39m=\u001b[39m ThriftObject\u001b[39m.\u001b[39mfrom_fields(\n\u001b[1;32m    786\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mRowGroup\u001b[39m\u001b[39m\"\u001b[39m, num_rows\u001b[39m=\u001b[39mrows, columns\u001b[39m=\u001b[39mcols,\n\u001b[1;32m    787\u001b[0m     total_byte_size\u001b[39m=\u001b[39m\u001b[39msum\u001b[39m([c\u001b[39m.\u001b[39mmeta_data\u001b[39m.\u001b[39mtotal_uncompressed_size \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m cols]))\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/fastparquet/writer.py:615\u001b[0m, in \u001b[0;36mwrite_column\u001b[0;34m(f, data0, selement, compression, datapage_version, stats)\u001b[0m\n\u001b[1;32m    611\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mint32\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m datapage_version \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    614\u001b[0m     bdata \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\n\u001b[0;32m--> 615\u001b[0m         repetition_data, definition_data, encode[encoding](data, selement), \u001b[39m8\u001b[39m \u001b[39m*\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\x00\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    616\u001b[0m     ])\n\u001b[1;32m    617\u001b[0m     dph \u001b[39m=\u001b[39m parquet_thrift\u001b[39m.\u001b[39mDataPageHeader(\n\u001b[1;32m    618\u001b[0m         num_values\u001b[39m=\u001b[39mcheck_32(row_end \u001b[39m-\u001b[39m row_start),\n\u001b[1;32m    619\u001b[0m         encoding\u001b[39m=\u001b[39m\u001b[39mgetattr\u001b[39m(parquet_thrift\u001b[39m.\u001b[39mEncoding, encoding),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    622\u001b[0m         i32\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    623\u001b[0m     )\n\u001b[1;32m    624\u001b[0m     l0 \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(bdata)\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/fastparquet/writer.py:373\u001b[0m, in \u001b[0;36mencode_plain\u001b[0;34m(data, se)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode_plain\u001b[39m(data, se):\n\u001b[1;32m    372\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"PLAIN encoding; returns byte representation\"\"\"\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m     out \u001b[39m=\u001b[39m convert(data, se)\n\u001b[1;32m    374\u001b[0m     \u001b[39mif\u001b[39;00m se\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m parquet_thrift\u001b[39m.\u001b[39mType\u001b[39m.\u001b[39mBYTE_ARRAY:\n\u001b[1;32m    375\u001b[0m         \u001b[39mreturn\u001b[39;00m pack_byte_array(\u001b[39mlist\u001b[39m(out))\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/fastparquet/writer.py:287\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(data, se)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    285\u001b[0m         ct \u001b[39m=\u001b[39m parquet_thrift\u001b[39m.\u001b[39mConvertedType\u001b[39m.\u001b[39m_VALUES_TO_NAMES[\n\u001b[1;32m    286\u001b[0m             converted_type] \u001b[39mif\u001b[39;00m converted_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError converting column \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m to bytes using \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    288\u001b[0m                          \u001b[39m'\u001b[39m\u001b[39mencoding \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m. Original error: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    289\u001b[0m                          \u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (data\u001b[39m.\u001b[39mname, ct, e))\n\u001b[1;32m    290\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mstr\u001b[39m(dtype) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstring\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    291\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Error converting column \"n_products\" to bytes using encoding UTF8. Original error: bad argument type for built-in operation"
     ]
    }
   ],
   "source": [
    "from pipeline.data import Ingredient, Product\n",
    "ing = Ingredient('data-contract.yml')\n",
    "# prd.store_processed()\n",
    "ing.processed.to_excel('./ingredients.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def extract_keys_values(df, column):\n",
    "    concerns_dict = {}\n",
    "\n",
    "    for d in df[column]:\n",
    "        if not isinstance(d, dict):\n",
    "            continue\n",
    "        for key, value_list in d.items():\n",
    "            if key not in concerns_dict:\n",
    "                concerns_dict[key] = set()\n",
    "            concerns_dict[key].update(value_list)\n",
    "\n",
    "    # Convert sets to lists\n",
    "    for key in concerns_dict:\n",
    "        concerns_dict[key] = list(concerns_dict[key])\n",
    "\n",
    "    return concerns_dict\n",
    "\n",
    "extract_keys_values(prd.processed, 'concern_list')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'brand', 'type', 'description_directions', 'ingredients',\n",
       "       'aspects', 'benefits', 'notable_ingredients', 'concerns'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd.interim.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "import numpy as np\n",
    "\n",
    "def extract_concerns_number(s):\n",
    "    match = re.search(r\"Concerns\\s*\\((\\d+)\\)\", s)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# def split_by_concerns(row):\n",
    "#     text = row['concerns']\n",
    "#     # check and remove the concerns header\n",
    "#     if isinstance(text, str):\n",
    "#         # print(f'{text=}')\n",
    "#         concerns = {}\n",
    "#         split_text = re.split('\\n+', text)\n",
    "#         if len(split_text) > 0:\n",
    "#             num_concerns = int(re.findall(\n",
    "#                 r'\\d+', split_text[0])[0]) if len(re.findall(r'\\d+', split_text[0])) > 0 else 0\n",
    "#             if int(num_concerns) == 0:\n",
    "#                 # print(' - error: no concerns')\n",
    "#                 concerns = np.nan\n",
    "#             else:    \n",
    "#                 num_concern_statements = len(re.findall('May', text))\n",
    "#                 if num_concerns == 0 or num_concerns == 0:\n",
    "#                     concerns = np.nan\n",
    "#                 else:\n",
    "#                     if num_concern_statements != num_concerns:\n",
    "#                         print(\n",
    "#                             f' - error: {num_concerns=} | {num_concern_statements=}')\n",
    "#                         concerns = np.nan\n",
    "#                     else:\n",
    "#                         split_text = [s for s in split_text if 'from' not in s]\n",
    "#                         split_text = split_text[1:]\n",
    "#                         for i, split in enumerate(split_text):\n",
    "#                             if 'May' in split:\n",
    "#                                 if \"â€¢\" in split_text[i+1]:\n",
    "#                                     ings = [i.strip() for i in split_text[i + 1].split(\"â€¢\")]\n",
    "#                                     ings = [i.rsplit(' ', 1)[0] if '%' in i else i for i in ings]\n",
    "                                    \n",
    "#                                 else:\n",
    "#                                     ings = [split_text[i+1].strip()]\n",
    "#                                     ings = [i.rsplit(' ', 1)[0] if '%' in i else i for i in ings]\n",
    "                                    \n",
    "#                                 concerns[split] = ings\n",
    "#         else:\n",
    "#             # print(' - error: no concern statements')\n",
    "#             concerns = np.nan\n",
    "#     else:\n",
    "#         concerns = np.nan\n",
    "        \n",
    "#     row['concern_list'] = concerns\n",
    "#     return row\n",
    "\n",
    "\n",
    "# processed_concerns = prd.interim.apply(split_by_concerns, axis=1)\n",
    "extract_keys_values(prd.processed, 'concern_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Concerns (3)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMay Worsen Dry Skin\\n\\n\\nfrom 2 ingredients\\n\\n\\n\\nSodium Chloride â€¢ Citric Acid\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMay Cause Acne\\n\\n\\nfrom 1 ingredient\\n\\n\\n\\nSodium Chloride\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMay Cause Irritation\\n\\n\\nfrom 1 ingredient\\n\\n\\n\\nCitric Acid'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>concern_list</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Niacinamide 10% + Zinc 1%</td>\n",
       "      <td>{'May Cause Irritation': ['Isoceteth-20']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advanced Snail 96 Mucin Power Essence</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Niacinamide 10% + Zinc 1%</td>\n",
       "      <td>{'May Cause Irritation': ['Isoceteth-20']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Advanced Snail 96 Mucin Power Essence</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10018</th>\n",
       "      <td>Baby Moisturizing Cream</td>\n",
       "      <td>{'May Worsen Oily Skin': ['Petrolatum'], 'May ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10019</th>\n",
       "      <td>Transforming Walnut Scrub</td>\n",
       "      <td>{'May Worsen Dry Skin': ['Sodium Chloride', 'C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10020</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10021</th>\n",
       "      <td>Clear Body Break-Out Free Liquid Lotion Sunscr...</td>\n",
       "      <td>{'May Cause Acne': ['Ethylhexyl Stearate'], 'M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10022</th>\n",
       "      <td>Triple Action Cleansing Water</td>\n",
       "      <td>{'May Worsen Dry Skin': ['Sodium Chloride', 'C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10023 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "                                                           \n",
       "0                              Niacinamide 10% + Zinc 1%   \n",
       "1                  Advanced Snail 96 Mucin Power Essence   \n",
       "2                              Niacinamide 10% + Zinc 1%   \n",
       "3                  Advanced Snail 96 Mucin Power Essence   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "10018                            Baby Moisturizing Cream   \n",
       "10019                          Transforming Walnut Scrub   \n",
       "10020                                                NaN   \n",
       "10021  Clear Body Break-Out Free Liquid Lotion Sunscr...   \n",
       "10022                      Triple Action Cleansing Water   \n",
       "\n",
       "                                            concern_list  \n",
       "                                                          \n",
       "0             {'May Cause Irritation': ['Isoceteth-20']}  \n",
       "1                                                    NaN  \n",
       "2             {'May Cause Irritation': ['Isoceteth-20']}  \n",
       "3                                                    NaN  \n",
       "4                                                    NaN  \n",
       "...                                                  ...  \n",
       "10018  {'May Worsen Oily Skin': ['Petrolatum'], 'May ...  \n",
       "10019  {'May Worsen Dry Skin': ['Sodium Chloride', 'C...  \n",
       "10020                                                NaN  \n",
       "10021  {'May Cause Acne': ['Ethylhexyl Stearate'], 'M...  \n",
       "10022  {'May Worsen Dry Skin': ['Sodium Chloride', 'C...  \n",
       "\n",
       "[10023 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "prd.processed[['name','concern_list']].fillna(np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'May Worsen Dry Skin': ['Salicylic Acid'],\n",
       " 'May Cause Irritation': ['Salicylic Acid'],\n",
       " 'May Worsen Eczema': ['Salicylic Acid']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "prd.processed.concern_list.iloc[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                  0.01\n",
      "description           0.01\n",
      "alias                99.97\n",
      "whereitsused          0.47\n",
      "n_products           81.00\n",
      "likes                 0.01\n",
      "dislikes              0.01\n",
      "rating               98.87\n",
      "type                 13.38\n",
      "benefits_concerns    64.61\n",
      "references           98.85\n",
      "cosing_data          74.56\n",
      "common_products      10.18\n",
      "dtype: float64\n",
      "41.69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>alias</th>\n",
       "      <th>whereitsused</th>\n",
       "      <th>n_products</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>rating</th>\n",
       "      <th>type</th>\n",
       "      <th>benefits_concerns</th>\n",
       "      <th>references</th>\n",
       "      <th>cosing_data</th>\n",
       "      <th>common_products</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Niacinamide</td>\n",
       "      <td>Description\\n\\n\\n\\n\\n\\n\\nNiacinamide has emerg...</td>\n",
       "      <td>Vitamin B3, Nicotinamide, and 3-Pyridinecarbox...</td>\n",
       "      <td>Where it's used\\n\\n\\n\\nNiacinamide is\\n\\nmost ...</td>\n",
       "      <td>1921</td>\n",
       "      <td>522</td>\n",
       "      <td>58</td>\n",
       "      <td>Liked</td>\n",
       "      <td>Smoothing</td>\n",
       "      <td>At a glance\\n\\n\\nHere's our breakdown of what ...</td>\n",
       "      <td>References\\n\\n\\n\\n\\nhttps://pubmed.ncbi.nlm.ni...</td>\n",
       "      <td>CosIng Data\\n\\n\\n\\n\\nCosIng ID: 35499INCI Name...</td>\n",
       "      <td>The Ordinary\\n\\n\\nNiacinamide 10% + Zinc 1%\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyaluronic Acid</td>\n",
       "      <td>Description\\n\\n\\n\\n\\n\\n\\nHyaluronic acid is na...</td>\n",
       "      <td>None</td>\n",
       "      <td>Where it's used\\n\\n\\n\\nHyaluronic Acid is\\n\\nm...</td>\n",
       "      <td>647</td>\n",
       "      <td>381</td>\n",
       "      <td>38</td>\n",
       "      <td>Liked</td>\n",
       "      <td>Humectant, Moisturising, Skin Conditioning</td>\n",
       "      <td>At a glance\\n\\n\\nHere's our breakdown of what ...</td>\n",
       "      <td>References\\n\\n\\n \\n\\nhttps://pubmed.ncbi.nlm.n...</td>\n",
       "      <td>CosIng Data\\n\\n\\n\\n\\nCosIng ID: 34315INCI Name...</td>\n",
       "      <td>CeraVe\\n\\n\\nRenewing SA Cleanser\\n\\n\\n\\n\\n$10....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Salicylic Acid</td>\n",
       "      <td>Description\\n\\n\\n\\n\\n\\n\\nSalicylic Acid (also ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Where it's used\\n\\n\\n\\nSalicylic Acid is\\n\\nmo...</td>\n",
       "      <td>870</td>\n",
       "      <td>251</td>\n",
       "      <td>47</td>\n",
       "      <td>Liked</td>\n",
       "      <td>Masking, Preservative, Skin Conditioning</td>\n",
       "      <td>At a glance\\n\\n\\nHere's our breakdown of what ...</td>\n",
       "      <td>References\\n\\n\\n\\n\\nhttps://pubmed.ncbi.nlm.ni...</td>\n",
       "      <td>CosIng Data\\n\\n\\n\\n\\nCosIng ID: 37595INCI Name...</td>\n",
       "      <td>Paula's Choice\\n\\n\\nSkin Perfecting 2% BHA Liq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Glycerin</td>\n",
       "      <td>Description\\n\\n\\n\\n\\n\\nGlycerin is already nat...</td>\n",
       "      <td>None</td>\n",
       "      <td>Where it's used\\n\\n\\n\\nGlycerin is\\n\\nmost oft...</td>\n",
       "      <td>8072</td>\n",
       "      <td>224</td>\n",
       "      <td>8</td>\n",
       "      <td>Loved</td>\n",
       "      <td>Humectant, Skin Conditioning, Skin Protecting,...</td>\n",
       "      <td>None</td>\n",
       "      <td>References\\n\\n\\n\\n\\nhttps://www.ncbi.nlm.nih.g...</td>\n",
       "      <td>Popular Products That Contain Glycerin\\n\\n\\n\\n...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Retinol</td>\n",
       "      <td>Description\\n\\n\\n\\n\\n\\n\\nRetinol, AKA Vitamin ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Where it's used\\n\\n\\n\\nRetinol is\\n\\nmost ofte...</td>\n",
       "      <td>275</td>\n",
       "      <td>201</td>\n",
       "      <td>31</td>\n",
       "      <td>Liked</td>\n",
       "      <td>Skin Conditioning</td>\n",
       "      <td>At a glance\\n\\n\\nHere's our breakdown of what ...</td>\n",
       "      <td>References\\n\\n\\n\\n\\nhttps://pubmed.ncbi.nlm.ni...</td>\n",
       "      <td>CosIng Data\\n\\n\\n\\n\\nCosIng ID: 37479INCI Name...</td>\n",
       "      <td>CeraVe\\n\\n\\nResurfacing Retinol Serum\\n\\n\\n\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15508</th>\n",
       "      <td>3-Amino-2,4-Dichlorophenol Hcl</td>\n",
       "      <td>Description\\n\\n\\n\\n\\n\\nWe don't have a descrip...</td>\n",
       "      <td>None</td>\n",
       "      <td>Where it's used\\n\\n\\n\\nIt is currently used\\n0...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CosIng Data\\n\\n\\n\\n\\nCosIng ID: 41538INCI Name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15509</th>\n",
       "      <td>3-Ethyl-3,7-Dimethyloct-6-Enal</td>\n",
       "      <td>Description\\n\\n\\n\\n\\n\\n\\n3-Ethyl-3,7-Dimethylo...</td>\n",
       "      <td>None</td>\n",
       "      <td>Where it's used\\n\\n\\n\\nIt is currently used\\n0...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Perfuming</td>\n",
       "      <td>At a glance\\n\\n\\nHere's our breakdown of what ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CosIng Data\\n\\n\\n\\n\\nCosIng ID: 39854INCI Name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15510</th>\n",
       "      <td>3-Isopentenyl 2-Isopentenoate</td>\n",
       "      <td>Description\\n\\n\\n\\n\\n\\n\\n3-Isopentenyl 2-Isope...</td>\n",
       "      <td>None</td>\n",
       "      <td>Where it's used\\n\\n\\n\\nIt is currently used\\n0...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Perfuming</td>\n",
       "      <td>At a glance\\n\\n\\nHere's our breakdown of what ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CosIng Data\\n\\n\\n\\n\\nCosIng ID: 39680INCI Name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15511</th>\n",
       "      <td>3-Methyl-5-(2,2,3-Trimethyl-3-Cyclopentenyl)Me...</td>\n",
       "      <td>Description\\n\\n\\n\\n\\n\\n\\n3-Methyl-5-(2,2,3-Tri...</td>\n",
       "      <td>None</td>\n",
       "      <td>Where it's used\\n\\n\\n\\nIt is currently used\\n0...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Perfuming</td>\n",
       "      <td>At a glance\\n\\n\\nHere's our breakdown of what ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CosIng Data\\n\\n\\n\\n\\nCosIng ID: 40823INCI Name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15512</th>\n",
       "      <td>3-Methyl-5-Propyl-2-Cyclohexenone</td>\n",
       "      <td>Description\\n\\n\\n\\n\\n\\n\\n3-Methyl-5-Propyl-2-C...</td>\n",
       "      <td>None</td>\n",
       "      <td>Where it's used\\n\\n\\n\\nIt is currently used\\n0...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Perfuming</td>\n",
       "      <td>At a glance\\n\\n\\nHere's our breakdown of what ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CosIng Data\\n\\n\\n\\n\\nCosIng ID: 40798INCI Name...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15512 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "                                                           \n",
       "1                                            Niacinamide   \n",
       "2                                        Hyaluronic Acid   \n",
       "3                                         Salicylic Acid   \n",
       "4                                               Glycerin   \n",
       "5                                                Retinol   \n",
       "...                                                  ...   \n",
       "15508                     3-Amino-2,4-Dichlorophenol Hcl   \n",
       "15509                     3-Ethyl-3,7-Dimethyloct-6-Enal   \n",
       "15510                      3-Isopentenyl 2-Isopentenoate   \n",
       "15511  3-Methyl-5-(2,2,3-Trimethyl-3-Cyclopentenyl)Me...   \n",
       "15512                  3-Methyl-5-Propyl-2-Cyclohexenone   \n",
       "\n",
       "                                             description  \\\n",
       "                                                           \n",
       "1      Description\\n\\n\\n\\n\\n\\n\\nNiacinamide has emerg...   \n",
       "2      Description\\n\\n\\n\\n\\n\\n\\nHyaluronic acid is na...   \n",
       "3      Description\\n\\n\\n\\n\\n\\n\\nSalicylic Acid (also ...   \n",
       "4      Description\\n\\n\\n\\n\\n\\nGlycerin is already nat...   \n",
       "5      Description\\n\\n\\n\\n\\n\\n\\nRetinol, AKA Vitamin ...   \n",
       "...                                                  ...   \n",
       "15508  Description\\n\\n\\n\\n\\n\\nWe don't have a descrip...   \n",
       "15509  Description\\n\\n\\n\\n\\n\\n\\n3-Ethyl-3,7-Dimethylo...   \n",
       "15510  Description\\n\\n\\n\\n\\n\\n\\n3-Isopentenyl 2-Isope...   \n",
       "15511  Description\\n\\n\\n\\n\\n\\n\\n3-Methyl-5-(2,2,3-Tri...   \n",
       "15512  Description\\n\\n\\n\\n\\n\\n\\n3-Methyl-5-Propyl-2-C...   \n",
       "\n",
       "                                                   alias  \\\n",
       "                                                           \n",
       "1      Vitamin B3, Nicotinamide, and 3-Pyridinecarbox...   \n",
       "2                                                   None   \n",
       "3                                                   None   \n",
       "4                                                   None   \n",
       "5                                                   None   \n",
       "...                                                  ...   \n",
       "15508                                               None   \n",
       "15509                                               None   \n",
       "15510                                               None   \n",
       "15511                                               None   \n",
       "15512                                               None   \n",
       "\n",
       "                                            whereitsused  n_products  likes  \\\n",
       "                                                                              \n",
       "1      Where it's used\\n\\n\\n\\nNiacinamide is\\n\\nmost ...        1921    522   \n",
       "2      Where it's used\\n\\n\\n\\nHyaluronic Acid is\\n\\nm...         647    381   \n",
       "3      Where it's used\\n\\n\\n\\nSalicylic Acid is\\n\\nmo...         870    251   \n",
       "4      Where it's used\\n\\n\\n\\nGlycerin is\\n\\nmost oft...        8072    224   \n",
       "5      Where it's used\\n\\n\\n\\nRetinol is\\n\\nmost ofte...         275    201   \n",
       "...                                                  ...         ...    ...   \n",
       "15508  Where it's used\\n\\n\\n\\nIt is currently used\\n0...        <NA>      0   \n",
       "15509  Where it's used\\n\\n\\n\\nIt is currently used\\n0...        <NA>      0   \n",
       "15510  Where it's used\\n\\n\\n\\nIt is currently used\\n0...        <NA>      0   \n",
       "15511  Where it's used\\n\\n\\n\\nIt is currently used\\n0...        <NA>      0   \n",
       "15512  Where it's used\\n\\n\\n\\nIt is currently used\\n0...        <NA>      0   \n",
       "\n",
       "       dislikes rating                                               type  \\\n",
       "                                                                            \n",
       "1            58  Liked                                          Smoothing   \n",
       "2            38  Liked         Humectant, Moisturising, Skin Conditioning   \n",
       "3            47  Liked           Masking, Preservative, Skin Conditioning   \n",
       "4             8  Loved  Humectant, Skin Conditioning, Skin Protecting,...   \n",
       "5            31  Liked                                  Skin Conditioning   \n",
       "...         ...    ...                                                ...   \n",
       "15508         0   None                                               None   \n",
       "15509         0   None                                          Perfuming   \n",
       "15510         0   None                                          Perfuming   \n",
       "15511         0   None                                          Perfuming   \n",
       "15512         0   None                                          Perfuming   \n",
       "\n",
       "                                       benefits_concerns  \\\n",
       "                                                           \n",
       "1      At a glance\\n\\n\\nHere's our breakdown of what ...   \n",
       "2      At a glance\\n\\n\\nHere's our breakdown of what ...   \n",
       "3      At a glance\\n\\n\\nHere's our breakdown of what ...   \n",
       "4                                                   None   \n",
       "5      At a glance\\n\\n\\nHere's our breakdown of what ...   \n",
       "...                                                  ...   \n",
       "15508                                               None   \n",
       "15509  At a glance\\n\\n\\nHere's our breakdown of what ...   \n",
       "15510  At a glance\\n\\n\\nHere's our breakdown of what ...   \n",
       "15511  At a glance\\n\\n\\nHere's our breakdown of what ...   \n",
       "15512  At a glance\\n\\n\\nHere's our breakdown of what ...   \n",
       "\n",
       "                                              references  \\\n",
       "                                                           \n",
       "1      References\\n\\n\\n\\n\\nhttps://pubmed.ncbi.nlm.ni...   \n",
       "2      References\\n\\n\\n \\n\\nhttps://pubmed.ncbi.nlm.n...   \n",
       "3      References\\n\\n\\n\\n\\nhttps://pubmed.ncbi.nlm.ni...   \n",
       "4      References\\n\\n\\n\\n\\nhttps://www.ncbi.nlm.nih.g...   \n",
       "5      References\\n\\n\\n\\n\\nhttps://pubmed.ncbi.nlm.ni...   \n",
       "...                                                  ...   \n",
       "15508                                               None   \n",
       "15509                                               None   \n",
       "15510                                               None   \n",
       "15511                                               None   \n",
       "15512                                               None   \n",
       "\n",
       "                                             cosing_data  \\\n",
       "                                                           \n",
       "1      CosIng Data\\n\\n\\n\\n\\nCosIng ID: 35499INCI Name...   \n",
       "2      CosIng Data\\n\\n\\n\\n\\nCosIng ID: 34315INCI Name...   \n",
       "3      CosIng Data\\n\\n\\n\\n\\nCosIng ID: 37595INCI Name...   \n",
       "4      Popular Products That Contain Glycerin\\n\\n\\n\\n...   \n",
       "5      CosIng Data\\n\\n\\n\\n\\nCosIng ID: 37479INCI Name...   \n",
       "...                                                  ...   \n",
       "15508                                               None   \n",
       "15509                                               None   \n",
       "15510                                               None   \n",
       "15511                                               None   \n",
       "15512                                               None   \n",
       "\n",
       "                                         common_products  \n",
       "                                                          \n",
       "1      The Ordinary\\n\\n\\nNiacinamide 10% + Zinc 1%\\n\\...  \n",
       "2      CeraVe\\n\\n\\nRenewing SA Cleanser\\n\\n\\n\\n\\n$10....  \n",
       "3      Paula's Choice\\n\\n\\nSkin Perfecting 2% BHA Liq...  \n",
       "4                                                   None  \n",
       "5      CeraVe\\n\\n\\nResurfacing Retinol Serum\\n\\n\\n\\n\\...  \n",
       "...                                                  ...  \n",
       "15508  CosIng Data\\n\\n\\n\\n\\nCosIng ID: 41538INCI Name...  \n",
       "15509  CosIng Data\\n\\n\\n\\n\\nCosIng ID: 39854INCI Name...  \n",
       "15510  CosIng Data\\n\\n\\n\\n\\nCosIng ID: 39680INCI Name...  \n",
       "15511  CosIng Data\\n\\n\\n\\n\\nCosIng ID: 40823INCI Name...  \n",
       "15512  CosIng Data\\n\\n\\n\\n\\nCosIng ID: 40798INCI Name...  \n",
       "\n",
       "[15512 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipeline.data import Ingredient\n",
    "from utils import *\n",
    "\n",
    "data_contract = read_yaml('data-contract.yml')\n",
    "ing = Ingredient(data_contract)\n",
    "ing.store_processed(True)\n",
    "ing.processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pystore.store(data_contract['Datastore']['path'])\n",
    "product_collection = store.collection(data_contract['Product']['name'])\n",
    "ingredient_collection = store.collection(data_contract['Product']['name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_ingredients = pd.read_excel('/Users/greysonnewton/Library/CloudStorage/OneDrive-Personal/cosnetix-pipeline/external/scraped/ingredients.xlsx')\n",
    "raw_products = pd.read_excel(\n",
    "    '/Users/greysonnewton/Library/CloudStorage/OneDrive-Personal/cosnetix-pipeline/external/scraped/products.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_collection.write(\n",
    "    data_contract['Product']['collections']['raw'], \n",
    "    raw_products,\n",
    "    metadata = {\n",
    "        'source':'scraped',\n",
    "        'last_updated':'2022-12-01'\n",
    "    }, \n",
    "    overwrite=True\n",
    "    )\n",
    "\n",
    "ingredient_collection.write(\n",
    "    data_contract['Ingredient']['collections']['raw'],\n",
    "    raw_products,\n",
    "    metadata={\n",
    "        'source': 'scraped',\n",
    "        'last_updated': '2022-12-01'\n",
    "    },\n",
    "    overwrite=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "def set_list_id(x, id_table):\n",
    "    if x is not np.nan and type(x) is not float and x is not None:\n",
    "        ids = []\n",
    "        for i in x:\n",
    "            i = i.lower().replace(' ', '_').strip()\n",
    "            if i in list(id_table.keys()):\n",
    "                ids.append(id_table[i])\n",
    "        return ids\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def n_nulls(df):\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        nulls = df.isnull().sum().sum()\n",
    "        print(nulls, f' - {round(nulls/len(df)*100,2)}% null in dataframe')\n",
    "    elif isinstance(df, pd.Series):\n",
    "        nulls = df.isnull().sum()\n",
    "        print(nulls, f' - {round(nulls/len(df)*100,2)}% null in series')\n",
    "    else:\n",
    "        print('Not a dataframe or series')\n",
    "\n",
    "\n",
    "def n_dupes(df):\n",
    "    print(df.duplicated().sum())\n",
    "\n",
    "\n",
    "def has_numbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "\n",
    "def find_percentages(inputString):\n",
    "    percentages = re.findall(\n",
    "        '(?<=\\d)[.]\\d{1,2}%|100%|\\d{1,2}%', inputString, re.IGNORECASE)\n",
    "    return percentages if len(percentages) > 0 else None\n",
    "\n",
    "\n",
    "def find_numbers(inputString):\n",
    "    numbers = re.findall('\\d{1,2}.\\d{1,2}', inputString)\n",
    "    return numbers if len(numbers) > 0 else None\n",
    "\n",
    "\n",
    "def find_positions(pattern, string):\n",
    "    positions = [match.span() for match in re.finditer(pattern, string)]\n",
    "    return positions if len(positions) > 0 else None\n",
    "\n",
    "\n",
    "def is_present(pattern, text):\n",
    "    return re.search(pattern, text) is not None\n",
    "\n",
    "\n",
    "def get_number(text):\n",
    "    match = re.search(r\"(?<=[^\\d\\.])\\d+(\\.\\d+)?(?=[^\\d\\.])\", text)\n",
    "    return int(match.group()) if match else None\n",
    "\n",
    "\n",
    "def split_string_on_consecutive_newlines(string, n):\n",
    "    return re.split(r'\\n{3,}', string)\n",
    "\n",
    "\n",
    "def scrub_cosing(text):\n",
    "    cosing_data = {}\n",
    "\n",
    "    cosing_id = np.nan\n",
    "    name = np.nan\n",
    "    num = np.nan\n",
    "    functions = np.nan\n",
    "\n",
    "    re_cosing = re.search(\"CosIng ID:\", text)\n",
    "    re_name = re.search(\"Name:\", text)\n",
    "\n",
    "    if re_cosing is not None and re_name is not None:\n",
    "        cosing_data['id'] = text[re_cosing.end():re_name.start()].strip()\n",
    "    else:\n",
    "        cosing_data['id'] = np.nan\n",
    "\n",
    "    re_num = re.search(\"#:\", text)\n",
    "    if re_name is not None and re_num is not None:\n",
    "        name = text[re_name.end():re_num.start()].strip()\n",
    "        if 'Name:' in name:\n",
    "            name = name.split('Name:')[1].strip()\n",
    "        cosing_data['name'] = name\n",
    "    else:\n",
    "        cosing_data['name'] = np.nan\n",
    "\n",
    "    re_function = re.search(\"Functions:\", text)\n",
    "    if re_function is not None and re_num is not None:\n",
    "        cosing_data['num'] = text[re_num.end():re_function.start()].strip()\n",
    "    else:\n",
    "        cosing_data['num'] = np.nan\n",
    "\n",
    "    if re_function is not None:\n",
    "        cosing_data['functions'] = [f.strip()\n",
    "                                    for f in text[re_function.end():].split(',')]\n",
    "    else:\n",
    "        cosing_data['functions'] = np.nan\n",
    "\n",
    "    return cosing_data\n",
    "\n",
    "\n",
    "def get_files(directory, file_type):\n",
    "    return glob.glob(directory + '/*.' + file_type)\n",
    "\n",
    "def all_nans(df:pd.DataFrame):\n",
    "    return round(df.isnull().sum().sum()/df.size*100,2)\n",
    "\n",
    "def col_nans(df: pd.DataFrame):\n",
    "    return round(df.isnull().sum()/len(df)*100, 2)\n",
    "\n",
    "\n",
    "def col_duplicates(df, column_name):\n",
    "    \"\"\"\n",
    "    Returns the total number of duplicates in the specified column of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        column_name (str): The name of the column to count duplicates in.\n",
    "\n",
    "    Returns:\n",
    "        int: The total number of duplicates in the specified column.\n",
    "    \"\"\"\n",
    "    duplicates = df[column_name].duplicated(keep='first').sum()\n",
    "    return duplicates\n",
    "\n",
    "def invert(d: dict):\n",
    "    return {v: k for k, v in d.items()} if d is not np.nan or d is not None else np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "class Product:\n",
    "    def __init__(self):\n",
    "        store = pystore.store(data_contract['Datastore']['path'])\n",
    "        self.collection = store.collection(data_contract['Product']['name'])\n",
    "    \n",
    "    @classmethod    \n",
    "    def store_raw(cls, file_path, overwrite=False):\n",
    "        data = pd.read_excel(file_path)\n",
    "        cls.collection.write(\n",
    "            data_contract['Product']['collections']['raw'],\n",
    "            data,\n",
    "            metadata={\n",
    "                'source': 'scraped',\n",
    "                'last_updated': '2022-12-01'\n",
    "            },\n",
    "            overwrite=overwrite\n",
    "        )\n",
    "\n",
    "class Ingredient:\n",
    "    def __init__(self):\n",
    "        store = pystore.store(data_contract['Datastore']['path'])\n",
    "        self.cfg = data_contract['Ingredient']\n",
    "        self.columns = self.cfg['columns']\n",
    "        self.collection = store.collection(self.cfg['name'])\n",
    "\n",
    "        \n",
    "    def store_raw(self, file_path, overwrite=False):\n",
    "        data = pd.read_excel(file_path)\n",
    "        self.collection.write(\n",
    "            self.cfg['collections']['raw'],\n",
    "            data,\n",
    "            metadata={\n",
    "                'source': 'scraped',\n",
    "                'last_updated': '2022-12-01'\n",
    "            },\n",
    "            overwrite=overwrite\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def raw(self):\n",
    "        try:\n",
    "            return self.collection.item(\n",
    "                self.cfg['collections']['raw']).to_pandas()\n",
    "        except Exception as e:\n",
    "            print('Raw data not found. Storing raw data...')\n",
    "            self.store_raw(\n",
    "                '/Users/greysonnewton/Library/CloudStorage/OneDrive-Personal/cosnetix-pipeline/external/scraped/ingredients.xlsx')\n",
    "            return self.collection.item(self.cfg['collections']['raw']).to_pandas()\n",
    "    \n",
    "    def store_interim(self, overwrite=False):\n",
    "        data = self.raw.copy(deep=True)\n",
    "        data.rename(columns={c: c.lower() for c in data.columns}, inplace=True)\n",
    "        data.replace('nan', np.nan, inplace=True)\n",
    "\n",
    "        data.drop_duplicates(subset='name', inplace=True)\n",
    "        data['ing_id'] = [i for i in range(1, len(data)+1)]\n",
    "        data.set_index('ing_id', inplace=True)             \n",
    "        data = data.fillna(np.nan)\n",
    "\n",
    "\n",
    "        # Regular expression pattern to match numbers followed by ' products'\n",
    "        pattern = r'(\\d+)\\s*products'\n",
    "\n",
    "        # Use str.extract() to extract the number from the strings in the column\n",
    "        extracted_numbers = data['n_products'].astype(\n",
    "            str).str.extract(pattern, expand=False)\n",
    "\n",
    "        # Convert matching values to float and non-matching values to NaN\n",
    "        data['n_products'] = pd.to_numeric(\n",
    "            extracted_numbers, errors='coerce')\n",
    "\n",
    "        data[['n_products', 'likes', 'dislikes']] = \\\n",
    "            data[['n_products','likes', 'dislikes']].apply(pd.to_numeric).astype('Int32')\n",
    "            \n",
    "        self.collection.write(\n",
    "            self.cfg['collections']['interim'],\n",
    "            data,\n",
    "            metadata={\n",
    "                'source': 'scraped',\n",
    "                'last_updated': '2022-12-01'\n",
    "            },\n",
    "            overwrite=overwrite\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def interim(self):\n",
    "        try:\n",
    "            return self.collection.item(self.cfg['collections']['interim']).to_pandas()\n",
    "        except Exception as e:\n",
    "            print('Interim data not found. Storing interim data...')\n",
    "            self.store_interim(True)\n",
    "            return self.collection.item(self.cfg['collections']['interim']).to_pandas()\n",
    "    \n",
    "    @interim.setter\n",
    "    def interim(self, overwrite=False):\n",
    "        self.store_interim(overwrite=overwrite)\n",
    "            \n",
    "    def store_processed(self, data, overwrite=False):\n",
    "        data = self.interim.fillna(np.nan)\n",
    "        data.apply(self.__scrub_desc, axis=1)\\\n",
    "            .apply(self.__scrub_whatitis_benefits, axis=1)\\\n",
    "            .apply(self.__scrub_uses_concentration, axis=1)\\\n",
    "            .apply(self.__scrub_type, axis=1)\\\n",
    "            .apply(self.__scrub_references, axis=1)\\\n",
    "            .apply(self.__scrub_cosing_data, axis=1)[self.columns]\n",
    "        \n",
    "        print(col_nans(data))\n",
    "        print(all_nans(data))\n",
    "\n",
    "        self.collection.write(\n",
    "            self.cfg['collections']['processed'],\n",
    "            data,\n",
    "            metadata={\n",
    "                'source': 'scraped',\n",
    "                'last_updated': '2022-12-01'\n",
    "            },\n",
    "            overwrite=overwrite\n",
    "        )\n",
    "    @property\n",
    "    def processed(self):\n",
    "        try:\n",
    "            return self.collection.item(self.cfg['collections']['processed']).to_pandas()\n",
    "        except Exception as e:\n",
    "            print('Processed data not found. Storing processed data...')\n",
    "            self.store_processed(True)\n",
    "            return self.collection.item(self.cfg['collections']['processed']).to_pandas()\n",
    "    \n",
    "    def __scrub_desc(self, row):\n",
    "        text = row['description']\n",
    "        if text is np.nan or text is not isinstance(text, str):\n",
    "            return row\n",
    "        desc = re.search(r'\\bDescription\\b', text, re.IGNORECASE)\n",
    "        alias = re.search(r'\\balso known as\\b', text, re.IGNORECASE)\n",
    "        usage_type = re.search(r'\\bWhat it does\\b', text, re.IGNORECASE)\n",
    "\n",
    "        # description\n",
    "        if desc is not None:\n",
    "            if alias is not None:\n",
    "                desc = text[desc.span()[1]:alias.span()[0]].strip()\n",
    "            else:\n",
    "                if usage_type is not None:\n",
    "                    desc = text[desc.span()[1]:usage_type.span()[0]].strip()\n",
    "                else:\n",
    "                    desc = text[desc.span()[1]:].strip()\n",
    "        else:\n",
    "            desc = np.nan\n",
    "        # alias\n",
    "        if alias is not None:\n",
    "            if usage_type is not None:\n",
    "                alias = text[alias.span()[1]:usage_type.span()[0]].strip().replace(\n",
    "                    '\\n', '').replace(':', '')\n",
    "            else:\n",
    "                alias = text[alias.span()[1]:].strip()\n",
    "        else:\n",
    "            alias = np.nan\n",
    "\n",
    "        # usage_type\n",
    "        if usage_type is not None:\n",
    "            usage_type = text[usage_type.span()[1]:].strip().replace(\n",
    "                ': ', '').replace(':', '')\n",
    "        else:\n",
    "            usage_type = np.nan\n",
    "\n",
    "        row['description'] = desc.replace('\\n', '')\n",
    "        row['alias'] = alias\n",
    "        row['usage_type'] = usage_type\n",
    "        return row\n",
    "\n",
    "    def __scrub_whatitis_benefits(self, row):\n",
    "        text = row['benefits_concerns']\n",
    "        if text is not np.nan and isinstance(text, str):\n",
    "            re_what_it_is = re.search(r'\\bWhat it is:\\s', text)\n",
    "            if re_what_it_is is None:\n",
    "                re_what_it_is = re.search(r'\\bWhat it is\\b', text)\n",
    "            re_benefits = re.search(r'\\bBenefits:\\s', text)\n",
    "            if re_benefits is None:\n",
    "                re_benefits = re.search(r'\\bBenefits\\b', text)\n",
    "\n",
    "            if re_what_it_is is None:\n",
    "                what_it_is = np.nan\n",
    "            else:\n",
    "                if re_benefits is not None:\n",
    "                    what_it_is = text[re_what_it_is.span()[1]:re_benefits.span()[\n",
    "                        0]].strip()\n",
    "                else:\n",
    "                    what_it_is = text[re_what_it_is.span()[1]:].strip()\n",
    "\n",
    "            if re_benefits is None:\n",
    "                benefits = np.nan\n",
    "            else:\n",
    "                benefits = text[re_benefits.span()[1]:].strip()\n",
    "                benefits_dict = {}\n",
    "                for b in benefits.split('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'):\n",
    "                    benefit = b.split('\\n\\n\\n')\n",
    "                    if len(benefit) > 1:\n",
    "                        benefits_dict[benefit[0]] = benefit[1]\n",
    "                benefits = benefits_dict\n",
    "\n",
    "            row['benefits'] = dict(\n",
    "                benefits) if benefits is not np.nan else np.nan\n",
    "            row['what_it_is'] = what_it_is\n",
    "\n",
    "        else:\n",
    "            row['benefits'] = np.nan\n",
    "            row['what_it_is'] = np.nan\n",
    "        return row\n",
    "\n",
    "    def __scrub_uses_concentration(self, row):\n",
    "\n",
    "        text = row['whereitsused']\n",
    "\n",
    "        if text is not np.nan and isinstance(text, str):\n",
    "            concentration = np.nan\n",
    "            n_routines = np.nan\n",
    "            categories = np.nan\n",
    "\n",
    "            if 'concentration' in text or 'concentrations' in text:\n",
    "                for sent in text.split('.'):\n",
    "                    if 'concentration' in sent or 'concentrations' in text:\n",
    "                        percentages = find_percentages(sent)\n",
    "                        if percentages is None:\n",
    "                            continue\n",
    "                        elif len(percentages) == 1:\n",
    "                            concentration = percentages[0]\n",
    "                        elif len(percentages) == 2:\n",
    "                            concentration = percentages[0] + \\\n",
    "                                ' - ' + percentages[1]\n",
    "                        else:\n",
    "                            print(percentages)\n",
    "                            continue\n",
    "\n",
    "            if 'skincare routines' in text or 'skincare routine' in text:\n",
    "                for sent in text.split('.'):\n",
    "                    if 'skincare routines' in sent or 'skincare routine' in sent:\n",
    "                        re_n_routines = find_numbers(sent)\n",
    "                        if re_n_routines is None:\n",
    "                            continue\n",
    "                        else:\n",
    "                            try:\n",
    "                                n_routines = int(re_n_routines[0])\n",
    "                            except Exception as e:\n",
    "                                print(e)\n",
    "                                print(sent)\n",
    "                                print(re_n_routines)\n",
    "                                quit()\n",
    "\n",
    "            re_categories = re.findall(r\"{y: (.*?)\\}\", text)\n",
    "            if len(re_categories) > 0:\n",
    "                categories = []\n",
    "                for cat in re_categories:\n",
    "                    if len(cat.split(',')) > 1:\n",
    "                        categories.append(cat.split(',')[0].replace(\"'\", ''))\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "            row['n_routines'] = n_routines\n",
    "            row['category'] = list(\n",
    "                categories) if categories is not np.nan else np.nan\n",
    "            row['concentration'] = concentration\n",
    "            return row\n",
    "        else:\n",
    "            row['n_routines'] = np.nan\n",
    "            row['category'] = np.nan\n",
    "            row['concentration'] = np.nan\n",
    "            return row\n",
    "\n",
    "    def __scrub_type(self, row):\n",
    "        x = row['type']\n",
    "        x.split(',') if isinstance(x,str) else np.nan\n",
    "        row['type'] = x\n",
    "        return row\n",
    "\n",
    "    def __scrub_references(self, row):\n",
    "        text = row['references']\n",
    "        if text is not np.nan and isinstance(text, str):\n",
    "            references = []\n",
    "            for link in text.split('https:'):\n",
    "                if '//' in link:\n",
    "                    references.append(f'https:{link.strip()}')\n",
    "            row['references'] = list(\n",
    "                references) if references is not np.nan else np.nan\n",
    "        else:\n",
    "            row['references'] = np.nan\n",
    "\n",
    "        return row\n",
    "\n",
    "    def __scrub_cosing_data(self, row):\n",
    "        text = row['cosing_data']\n",
    "        if text is not np.nan and isinstance(text, str):\n",
    "            scrubbed = scrub_cosing(text)\n",
    "            row['cosing_data'] = dict(\n",
    "                scrubbed) if scrubbed is not np.nan else np.nan\n",
    "            return row\n",
    "        else:\n",
    "            text = row['common_products']\n",
    "            if text is not np.nan and isinstance(text, str) and 'cosing' in text.lower():\n",
    "                scrubbed = scrub_cosing(text)\n",
    "                row['cosing_data'] = dict(\n",
    "                    scrubbed) if scrubbed is not np.nan and isinstance(scrubbed,str) else np.nan\n",
    "                return row\n",
    "            else:\n",
    "                row['cosing_data'] = np.nan\n",
    "                return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16773, 13)\n",
      "(15512, 13)\n",
      "(15512, 13)\n",
      "name                  0.01\n",
      "description           0.01\n",
      "alias                99.97\n",
      "whereitsused          0.47\n",
      "n_products           81.00\n",
      "likes                 0.01\n",
      "dislikes              0.01\n",
      "rating               98.87\n",
      "type                 13.38\n",
      "benefits_concerns    64.61\n",
      "references           98.85\n",
      "cosing_data          74.56\n",
      "common_products      10.18\n",
      "dtype: float64\n",
      "41.69\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "ing = Ingredient()\n",
    "print(ing.raw.shape)\n",
    "print(ing.interim.shape)\n",
    "print(ing.processed.shape)\n",
    "print(col_nans(ing.processed))\n",
    "print(all_nans(ing.processed))\n",
    "print(col_duplicates(ing.processed, 'name'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              n_products  extracted_number\n",
      "0          1921 products            1921.0\n",
      "1           300 products             300.0\n",
      "2                    NaN               NaN\n",
      "3                   None               NaN\n",
      "4  No products available               NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'n_products': [\n",
    "        '1921 products', '300 products', np.nan, None, 'No products available']\n",
    "})\n",
    "\n",
    "# Regular expression pattern to match numbers followed by ' products'\n",
    "pattern = r'(\\d+)\\s*products'\n",
    "\n",
    "# Use str.extract() to extract the number from the strings in the column\n",
    "df['extracted_number'] = df['n_products'].astype(\n",
    "    str).str.extract(pattern, expand=False).astype(float)\n",
    "\n",
    "# Replace non-matching values with NaN\n",
    "df['extracted_number'] = np.where(\n",
    "    df['extracted_number'].isnull(), np.nan, df['extracted_number'])\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Item `processed` doesn't exist. Create it using collection.write(`processed`, data, ...)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m store \u001b[39m=\u001b[39m pystore\u001b[39m.\u001b[39mstore(data_contract[\u001b[39m'\u001b[39m\u001b[39mDatastore\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m collection \u001b[39m=\u001b[39m store\u001b[39m.\u001b[39mcollection(data_contract[\u001b[39m'\u001b[39m\u001b[39mIngredient\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m collection\u001b[39m.\u001b[39;49mitem(\u001b[39m'\u001b[39;49m\u001b[39mprocessed\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/pystore/collection.py:76\u001b[0m, in \u001b[0;36mCollection.item\u001b[0;34m(self, item, snapshot, filters, columns)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mitem\u001b[39m(\u001b[39mself\u001b[39m, item, snapshot\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, filters\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, columns\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m Item(item, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatastore, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollection,\n\u001b[1;32m     77\u001b[0m                 snapshot, filters, columns, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/venvs/cosnetix_webapp/lib/python3.10/site-packages/pystore/item.py:42\u001b[0m, in \u001b[0;36mItem.__init__\u001b[0;34m(self, item, datastore, collection, snapshot, filters, columns, engine)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mmake_path(datastore, collection, item)\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path\u001b[39m.\u001b[39mexists():\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     43\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mItem `\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m` doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt exist. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     44\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCreate it using collection.write(`\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m`, data, ...)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[1;32m     45\u001b[0m             item, item))\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m snapshot:\n\u001b[1;32m     47\u001b[0m     snap_path \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mmake_path(\n\u001b[1;32m     48\u001b[0m         datastore, collection, \u001b[39m\"\u001b[39m\u001b[39m_snapshots\u001b[39m\u001b[39m\"\u001b[39m, snapshot)\n",
      "\u001b[0;31mValueError\u001b[0m: Item `processed` doesn't exist. Create it using collection.write(`processed`, data, ...)"
     ]
    }
   ],
   "source": [
    "store = pystore.store(data_contract['Datastore']['path'])\n",
    "collection = store.collection(data_contract['Ingredient']['name'])\n",
    "try:\n",
    "    collection.item('processed')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    collection.create_item('processed')\n",
    "    print('Created item: processed')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_collection.item(data_contract['Ingredient']['collections']['raw']).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ingredient:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    @property"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosnetix_webapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84c51f526eb5bdc9c19c7f8c6811f3049041f29f502b3b96bb7d09f43a1b7a23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
